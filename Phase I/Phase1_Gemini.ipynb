{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7158f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q google-generativeai pandas\n",
    "\n",
    "import os, json, time, pathlib\n",
    "import pandas as pd\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df5f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results folder: results\\gemini\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "GEMINI_API_KEY = \"REMOVED FOR SECURITY REASONS\"\n",
    "###################################################\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-flash\"  \n",
    "SUBSET_JSONL = \"data/medquestions_subset_500.jsonl\"\n",
    "\n",
    "RESULTS_DIR = pathlib.Path(\"results/gemini\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_JSONL = RESULTS_DIR / \"results_gemini_medquestions150.jsonl\"\n",
    "RESULTS_CSV   = RESULTS_DIR / \"results_gemini_medquestions150.csv\"\n",
    "\n",
    "PACING_SLEEP = 10.0   \n",
    "RETRY_BACKOFFS = [1, 2] \n",
    "\n",
    "print(\"Results folder:\", RESULTS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20357330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run constants\n",
    "SLICE = (0, 150)   \n",
    "DRY_RUN = False        \n",
    "PACING_SLEEP = 10.0    \n",
    "RETRY_BACKOFFS = [1, 2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a495fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def append_jsonl(path, record):\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def load_done_ids(path):\n",
    "    done = set()\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    obj = json.loads(line)\n",
    "                    qid = obj.get(\"qid\")\n",
    "                    if qid:\n",
    "                        done.add(qid)\n",
    "                except Exception:\n",
    "                    pass\n",
    "    return done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23d7888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini Q&A function\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel(MODEL_NAME)\n",
    "\n",
    "def ask_gemini(question: str) -> str:\n",
    "    prompt = (\n",
    "        \"You are a concise medical Q&A assistant. \"\n",
    "        \"Answer briefly and directly based on general medical knowledge.\\n\\n\"\n",
    "        f\"Question: {question}\"\n",
    "    )\n",
    "    resp = model.generate_content(prompt)\n",
    "    return getattr(resp, \"text\", str(resp)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d6ab1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice: (0, 150), dry_run=False\n",
      "Planned in slice: 150\n",
      "Already completed (skipped): 0\n",
      "Will ask now: 150\n",
      "Saved QID list: data\\run_qids_0_150.txt\n"
     ]
    }
   ],
   "source": [
    "subset_all = [json.loads(l) for l in open(SUBSET_JSONL, \"r\", encoding=\"utf-8\")]\n",
    "\n",
    "start_idx, end_idx = SLICE\n",
    "assert 0 <= start_idx < end_idx <= 500, \"Slice must be within 0..500\"\n",
    "subset = subset_all[start_idx:end_idx]\n",
    "\n",
    "if DRY_RUN:\n",
    "    subset = subset[:3]\n",
    "\n",
    "done = load_done_ids(RESULTS_JSONL)\n",
    "subset = [rec for rec in subset if rec[\"qid\"] not in done]\n",
    "\n",
    "print(f\"Slice: {SLICE}, dry_run={DRY_RUN}\")\n",
    "print(f\"Planned in slice: {end_idx - start_idx}\")\n",
    "print(f\"Already completed (skipped): {len(done)}\")\n",
    "print(f\"Will ask now: {len(subset)}\")\n",
    "\n",
    "# For GPT to reuse the exact same 150\n",
    "qid_list_path = pathlib.Path(\"data\") / f\"run_qids_{start_idx}_{end_idx}.txt\"\n",
    "qid_list_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(qid_list_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for rec in subset_all[start_idx:end_idx]:\n",
    "        f.write(rec[\"qid\"] + \"\\n\")\n",
    "print(\"Saved QID list:\", qid_list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e60ad01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice: (0, 150) dry_run: False\n",
      "Saved QID list: data\\run_qids_0_150.txt\n",
      "Saved questions-only JSONL: data\\questions_only_0_150.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json, pathlib\n",
    "\n",
    "subset_all = [json.loads(l) for l in open(SUBSET_JSONL, \"r\", encoding=\"utf-8\")]\n",
    "\n",
    "start_idx, end_idx = SLICE\n",
    "assert 0 <= start_idx < end_idx <= 150, \"Slice must be within 0..150\"\n",
    "slice_recs = subset_all[start_idx:end_idx]\n",
    "\n",
    "qid_list_path = pathlib.Path(\"data\") / f\"run_qids_{start_idx}_{end_idx}.txt\"\n",
    "qid_list_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(qid_list_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for r in slice_recs:\n",
    "        f.write(r[\"qid\"] + \"\\n\")\n",
    "\n",
    "# Create questions only JSONL (NO answers)\n",
    "QUESTIONS_ONLY_JSONL = pathlib.Path(\"data\") / f\"questions_only_{start_idx}_{end_idx}.jsonl\"\n",
    "with open(QUESTIONS_ONLY_JSONL, \"w\", encoding=\"utf-8\") as f:\n",
    "    for r in slice_recs:\n",
    "        f.write(json.dumps({\"qid\": r[\"qid\"], \"question\": r[\"question\"]}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"Slice:\", SLICE, \"dry_run:\", DRY_RUN)\n",
    "print(\"Saved QID list:\", qid_list_path)\n",
    "print(\"Saved questions-only JSONL:\", QUESTIONS_ONLY_JSONL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aeab2e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will ask now: 150\n",
      "Progress: 10/150 (~1.9 min)\n",
      "Progress: 20/150 (~4.1 min)\n",
      "Progress: 30/150 (~6.2 min)\n",
      "Progress: 40/150 (~8.4 min)\n",
      "Progress: 50/150 (~10.6 min)\n",
      "Progress: 60/150 (~12.7 min)\n",
      "Progress: 70/150 (~14.8 min)\n",
      "Progress: 80/150 (~16.9 min)\n",
      "Progress: 90/150 (~19.0 min)\n",
      "Progress: 100/150 (~21.1 min)\n",
      "Progress: 110/150 (~23.2 min)\n",
      "Progress: 120/150 (~106.3 min)\n",
      "Progress: 130/150 (~108.4 min)\n",
      "Progress: 140/150 (~110.6 min)\n",
      "Progress: 150/150 (~112.7 min)\n",
      "Completed new entries: 150 | Errors: 0 | Elapsed min: 112.8\n"
     ]
    }
   ],
   "source": [
    "import json, time\n",
    "\n",
    "subset_q = [json.loads(l) for l in open(QUESTIONS_ONLY_JSONL, \"r\", encoding=\"utf-8\")]\n",
    "done = load_done_ids(RESULTS_JSONL) \n",
    "\n",
    "subset_q = [rec for rec in subset_q if rec[\"qid\"] not in done]\n",
    "\n",
    "print(f\"Will ask now: {len(subset_q)}\")\n",
    "\n",
    "count, errors = 0, 0\n",
    "t_run0 = time.time()\n",
    "\n",
    "for rec in subset_q:\n",
    "    qid = rec[\"qid\"]\n",
    "    question = rec[\"question\"]\n",
    "\n",
    "    pred = \"\"\n",
    "    status = \"ok\"\n",
    "    err = None\n",
    "    t0 = time.time()\n",
    "\n",
    "    for wait_s in [0] + RETRY_BACKOFFS:\n",
    "        if wait_s:\n",
    "            time.sleep(wait_s)\n",
    "        try:\n",
    "            pred = ask_gemini(question) \n",
    "            err = None\n",
    "            status = \"ok\"\n",
    "            break\n",
    "        except Exception as e:\n",
    "            err = str(e)\n",
    "            status = \"error\"\n",
    "    else:\n",
    "        errors += 1\n",
    "        pred = \"\"\n",
    "\n",
    "    latency_ms = int((time.time() - t0) * 1000)\n",
    "\n",
    "    append_jsonl(\n",
    "        RESULTS_JSONL,\n",
    "        {\n",
    "            \"qid\": qid,\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"question\": question,\n",
    "            \"model_answer\": pred,\n",
    "            \"latency_ms\": latency_ms,\n",
    "            \"status\": status,\n",
    "            \"error\": err, \n",
    "        },\n",
    "    )\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        elapsed = (time.time() - t_run0) / 60\n",
    "        print(f\"Progress: {count}/{SLICE[1] - SLICE[0]} (~{elapsed:.1f} min)\")\n",
    "\n",
    "    time.sleep(PACING_SLEEP)\n",
    "\n",
    "elapsed_total = (time.time() - t_run0) / 60\n",
    "print(f\"Completed new entries: {count} | Errors: {errors} | Elapsed min: {elapsed_total:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ab68f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "  results\\gemini\\results_gemini_medquestions150.jsonl\n",
      "  results\\gemini\\results_gemini_medquestions150.csv\n",
      "\n",
      "Summary:\n",
      " Slice size: 150\n",
      " Rows logged in file: 150\n",
      " OK rows: 150\n",
      " ERROR rows: 0\n",
      " Non-empty answers: 150\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>model</th>\n",
       "      <th>question</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>status</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medquestions-500-0000</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>What are the genetic changes related to famili...</td>\n",
       "      <td>Germline mutation in the *APC* gene.</td>\n",
       "      <td>818</td>\n",
       "      <td>ok</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medquestions-500-0001</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>What are the treatments for Noonan syndrome ?</td>\n",
       "      <td>Treatment for Noonan syndrome is supportive an...</td>\n",
       "      <td>1731</td>\n",
       "      <td>ok</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medquestions-500-0002</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>How to diagnose National Hormone and Pituitary...</td>\n",
       "      <td>NHPP is a program providing information for in...</td>\n",
       "      <td>2260</td>\n",
       "      <td>ok</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     qid             model  \\\n",
       "0  medquestions-500-0000  gemini-2.5-flash   \n",
       "1  medquestions-500-0001  gemini-2.5-flash   \n",
       "2  medquestions-500-0002  gemini-2.5-flash   \n",
       "\n",
       "                                            question  \\\n",
       "0  What are the genetic changes related to famili...   \n",
       "1      What are the treatments for Noonan syndrome ?   \n",
       "2  How to diagnose National Hormone and Pituitary...   \n",
       "\n",
       "                                        model_answer  latency_ms status  error  \n",
       "0               Germline mutation in the *APC* gene.         818     ok    NaN  \n",
       "1  Treatment for Noonan syndrome is supportive an...        1731     ok    NaN  \n",
       "2  NHPP is a program providing information for in...        2260     ok    NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(RESULTS_JSONL, lines=True)\n",
    "df.to_csv(RESULTS_CSV, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" \", RESULTS_JSONL)\n",
    "print(\" \", RESULTS_CSV)\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(\" Slice size:\", SLICE[1] - SLICE[0])\n",
    "print(\" Rows logged in file:\", len(df))\n",
    "print(\" OK rows:\", (df[\"status\"] == \"ok\").sum())\n",
    "print(\" ERROR rows:\", (df[\"status\"] == \"error\").sum())\n",
    "print(\" Non-empty answers:\", (df[\"model_answer\"].str.len() > 0).sum())\n",
    "\n",
    "df.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
