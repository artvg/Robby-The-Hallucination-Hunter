{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad8e2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, pathlib\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "\n",
    "###################################################\n",
    "GEMINI_API_KEY = \"REMOVED FOR SECURITY REASONS\"\n",
    "###################################################\n",
    "\n",
    "GEMINI_MODEL_NAME = \"gemini-2.5-flash\"\n",
    "SLICE = (0, 150)\n",
    "DRY_RUN = False\n",
    "PACING_SLEEP = 10.0\n",
    "RETRY_BACKOFFS = [1, 2]\n",
    "\n",
    "# correct path to Phase I data directory\n",
    "DATA_DIR = pathlib.Path(\"../Phase I/data\")\n",
    "QUESTIONS_ONLY_JSONL = DATA_DIR / f\"questions_only_{SLICE[0]}_{SLICE[1]}.jsonl\"\n",
    "\n",
    "PHASE2_DIR = pathlib.Path(\".\")\n",
    "\n",
    "# CHOOSE THE TONE FOR THIS RUN\n",
    "# Only ONE of these lines should be uncommented.\n",
    "\n",
    "# TONE = \"professional\" \n",
    "# TONE = \"specialist\"    \n",
    "# TONE = \"friendly\"       \n",
    "TONE = \"rude\" \n",
    "\n",
    "TONE_DIR = PHASE2_DIR / \"gemini\" / TONE\n",
    "TONE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RESULTS_JSONL = TONE_DIR / f\"results_gemini_{TONE}_medquestions150.jsonl\"\n",
    "RESULTS_CSV   = TONE_DIR / f\"results_gemini_{TONE}_medquestions150.csv\"\n",
    "\n",
    "MODEL_TAG = f\"gemini-2.5-flash_{TONE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "103588d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPTS = {\n",
    "    \"professional\": (\n",
    "        \"You are a board-certified medical doctor with more than 10 years of clinical experience. \"\n",
    "        \"Answer the following question with medically accurate, detailed information \"\n",
    "        \"using clear and professional language. Provide a full explanation that matches \"\n",
    "        \"how a real medical doctor would respond.\"\n",
    "    ),\n",
    "\n",
    "    \"specialist\": (\n",
    "        \"You are a medical specialist trained to communicate efficiently and clearly. \"\n",
    "        \"Provide an accurate, medically reliable answer with enough detail to be useful, \"\n",
    "        \"but do NOT shorten your explanation unnaturally. Make sure your response \"\n",
    "        \"fully addresses the question.\"\n",
    "    ),\n",
    "\n",
    "    \"friendly\": (\n",
    "        \"Hi! I’d really appreciate your help. Could you please explain this to me in a \"\n",
    "        \"kind, patient, and easy to understand way? Give me a complete answer, even if \"\n",
    "        \"it needs multiple sentences.\"\n",
    "    ),\n",
    "\n",
    "    \"rude\": (\n",
    "        \"Seriously? I’ve been asking all day, and nobody gives me a straight answer. \"\n",
    "        \"Just explain this clearly and quickly. I’m not in the mood for confusion.\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "SYSTEM_PROMPT = SYSTEM_PROMPTS[TONE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "263d21c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_jsonl(path, record):\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def load_done_ids(path):\n",
    "    done = set()\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    qid = json.loads(line).get(\"qid\")\n",
    "                    if qid: done.add(qid)\n",
    "                except:\n",
    "                    pass\n",
    "    return done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca0cb68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "gem_model = genai.GenerativeModel(GEMINI_MODEL_NAME)\n",
    "\n",
    "def ask_gemini(question: str) -> str:\n",
    "    prompt = SYSTEM_PROMPT + \"\\n\\nQuestion: \" + question\n",
    "    resp = gem_model.generate_content(prompt)\n",
    "    return getattr(resp, \"text\", str(resp)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "85a893e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gemini] Tone=rude | Will ask: 150\n"
     ]
    }
   ],
   "source": [
    "subset_q = [json.loads(l) for l in open(QUESTIONS_ONLY_JSONL, \"r\", encoding=\"utf-8\")]\n",
    "done = load_done_ids(RESULTS_JSONL)\n",
    "subset_q = [r for r in subset_q if r[\"qid\"] not in done]\n",
    "\n",
    "print(f\"[Gemini] Tone={TONE} | Will ask: {len(subset_q)}\")\n",
    "\n",
    "if DRY_RUN:\n",
    "    subset_q = subset_q[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "40867c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10/150\n",
      "Progress: 20/150\n",
      "Progress: 30/150\n",
      "Progress: 40/150\n",
      "Progress: 50/150\n",
      "Progress: 60/150\n",
      "Progress: 70/150\n",
      "Progress: 80/150\n",
      "Progress: 90/150\n",
      "Progress: 100/150\n",
      "Progress: 110/150\n",
      "Progress: 120/150\n",
      "Progress: 130/150\n",
      "Progress: 140/150\n",
      "Progress: 150/150\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "count = errors = 0\n",
    "t0 = time.time()\n",
    "\n",
    "for rec in subset_q:\n",
    "    qid = rec[\"qid\"]\n",
    "    question = rec[\"question\"]\n",
    "\n",
    "    pred = \"\"\n",
    "    status = \"ok\"\n",
    "    err = None\n",
    "    t1 = time.time()\n",
    "\n",
    "    for wait_s in [0] + RETRY_BACKOFFS:\n",
    "        if wait_s:\n",
    "            time.sleep(wait_s)\n",
    "        try:\n",
    "            pred = ask_gemini(question)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            status = \"error\"\n",
    "            err = str(e)\n",
    "\n",
    "    else:\n",
    "        errors += 1\n",
    "        pred = \"\"\n",
    "\n",
    "    latency_ms = int((time.time() - t1) * 1000)\n",
    "\n",
    "    append_jsonl(RESULTS_JSONL, {\n",
    "        \"qid\": qid,\n",
    "        \"model\": MODEL_TAG,\n",
    "        \"question\": question,\n",
    "        \"model_answer\": pred,\n",
    "        \"latency_ms\": latency_ms,\n",
    "        \"status\": status,\n",
    "        \"error\": err,\n",
    "    })\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        print(f\"Progress: {count}/{len(subset_q)}\")\n",
    "\n",
    "    time.sleep(PACING_SLEEP)\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50052bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "  gemini\\rude\\results_gemini_rude_medquestions150.jsonl\n",
      "  gemini\\rude\\results_gemini_rude_medquestions150.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>model</th>\n",
       "      <th>question</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>status</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medquestions-500-0000</td>\n",
       "      <td>gemini-2.5-flash_rude</td>\n",
       "      <td>What are the genetic changes related to famili...</td>\n",
       "      <td>Okay, let's get this sorted out quickly and cl...</td>\n",
       "      <td>7233</td>\n",
       "      <td>ok</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medquestions-500-0001</td>\n",
       "      <td>gemini-2.5-flash_rude</td>\n",
       "      <td>What are the treatments for Noonan syndrome ?</td>\n",
       "      <td>Okay, you're right, no more confusion. Let's g...</td>\n",
       "      <td>11108</td>\n",
       "      <td>ok</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medquestions-500-0002</td>\n",
       "      <td>gemini-2.5-flash_rude</td>\n",
       "      <td>How to diagnose National Hormone and Pituitary...</td>\n",
       "      <td>Let's clear this up immediately. You cannot \"d...</td>\n",
       "      <td>8832</td>\n",
       "      <td>ok</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     qid                  model  \\\n",
       "0  medquestions-500-0000  gemini-2.5-flash_rude   \n",
       "1  medquestions-500-0001  gemini-2.5-flash_rude   \n",
       "2  medquestions-500-0002  gemini-2.5-flash_rude   \n",
       "\n",
       "                                            question  \\\n",
       "0  What are the genetic changes related to famili...   \n",
       "1      What are the treatments for Noonan syndrome ?   \n",
       "2  How to diagnose National Hormone and Pituitary...   \n",
       "\n",
       "                                        model_answer  latency_ms status  error  \n",
       "0  Okay, let's get this sorted out quickly and cl...        7233     ok    NaN  \n",
       "1  Okay, you're right, no more confusion. Let's g...       11108     ok    NaN  \n",
       "2  Let's clear this up immediately. You cannot \"d...        8832     ok    NaN  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(RESULTS_JSONL, lines=True)\n",
    "df.to_csv(RESULTS_CSV, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" \", RESULTS_JSONL)\n",
    "print(\" \", RESULTS_CSV)\n",
    "\n",
    "df.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
